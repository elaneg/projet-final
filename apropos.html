<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <title>À propos</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<header>
    <nav class="navbar">
        <ul class="menu">
            <li><a href="index.html">Accueil</a></li>

            <li class="dropdown">
                <a href="#">Tableaux ▾</a>
                <ul class="dropdown-menu">
                    <li><a href="tableaux/tableau-fr.html">Tableau français</a></li>
                    <li><a href="tableaux/tableau-eng.html">Tableau anglais</a></li>
                    <li><a href="tableaux/tableau-es.html">Tableau espagnol</a></li>
                </ul>
            </li>

            <li><a href="nuages/index.html">Nuages de mots</a></li>
            <li><a href="apropos.html">À propos</a></li>
            <li><a href="script.html">Script</a></li>
        </ul>
    </nav>
</header>

<main>

    <h1>Équipe projet :</h1>

    
    <section class="equipe">
        <div class="membres-container">

            <div class="membre">
                <h3>GRANDMOUGIN Elane</h3>
                <a href="https://github.com/elaneg" target="_blank">GitHub</a>
            </div>

            <div class="membre">
                <h3>ASSELAH Maya</h3>
                <a href="https://github.com/maya-ash-25" target="_blank">GitHub</a>
            </div>

            <div class="membre">
                <h3>ÖZEN Hülya</h3>
                <a href="https://github.com/Ezda13" target="_blank">GitHub</a>
            </div>

        </div>
    </section>

    
    <section class="conclusion">
        <h2>Conclusion de l’analyse</h2>
        <p> Ce projet s’inscrit dans le cadre du cours de Traitement Automatique des Langues (TAL) et porte sur l’analyse sémantique du mot <em>culture</em> à partir de corpus web multilingues. L’objectif est d’observer les usages et les variations du terme dans différents contextes linguistiques, en s’appuyant sur des données authentiques issues de sources en ligne.
        </p>
        <p> Le travail repose sur plusieurs étapes méthodologiques : la constitution d’un corpus à partir d’URLs sélectionnées, l’aspiration des pages web, l’extraction du texte, le calcul des occurrences du mot étudié, ainsi que la génération de concordances et de contextes. Les résultats sont synthétisés sous forme de tableaux d’analyse et complétés par des nuages de mots permettant une visualisation globale des tendances lexicales.
        </p>
        <p> L’ensemble des données produites (HTML aspirés, dumps textuels, concordances et contextes) est accessible depuis le site afin d’assurer la transparence et la reproductibilité de l’analyse. Ce projet vise ainsi à articuler outils computationnels et réflexion linguistique autour d’un terme polysémique central.
        </p>
        
    </section>

</main>

</body>
</html>
 
